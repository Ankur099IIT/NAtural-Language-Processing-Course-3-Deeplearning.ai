{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generating text with Neural Networks-(Make your own song).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOzrrJwZnJQtUxuiNubdU1g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ankur099IIT/Natural-Language-Processing-Course-3-Deeplearning.ai/blob/main/Generating_text_with_Neural_Networks_(Make_your_own_song).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaUWB_xJX3u0",
        "outputId": "5792dd75-6df2-4684-a0eb-9aa192659be7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['in the town of athy one jeremy lanigan ', ' battered away til he hadnt a pound. ', 'his father died and made him a man again ', ' left him a farm and ten acres of ground. ', 'he gave a grand party for friends and relations ', 'who didnt forget him when come to the wall, ', 'and if youll but listen ill make your eyes glisten ', 'of the rows and the ructions of lanigans ball. ', 'myself to be sure got free invitation, ', 'for all the nice girls and boys i might ask, ', 'and just in a minute both friends and relations ', 'were dancing round merry as bees round a cask. ', 'judy odaly, that nice little milliner, ', 'she tipped me a wink for to give her a call, ', 'and i soon arrived with peggy mcgilligan ', 'just in time for lanigans ball. ', 'there were lashings of punch and wine for the ladies, ', 'potatoes and cakes; there was bacon and tea, ', 'there were the nolans, dolans, ogradys ', 'courting the girls and dancing away. ', 'songs they went round as plenty as water, ', 'the harp that once sounded in taras old hall,', 'sweet nelly gray and the rat catchers daughter,', 'all singing together at lanigans ball. ', 'they were doing all kinds of nonsensical polkas ', 'all round the room in a whirligig. ', 'julia and i, we banished their nonsense ', 'and tipped them the twist of a reel and a jig. ', 'ach mavrone, how the girls got all mad at me ', 'danced til youd think the ceiling would fall. ', 'for i spent three weeks at brooks academy ', 'learning new steps for lanigans ball. ', 'three long weeks i spent up in dublin, ', 'three long weeks to learn nothing at all,', ' three long weeks i spent up in dublin, ', 'learning new steps for lanigans ball. ', 'she stepped out and i stepped in again, ', 'i stepped out and she stepped in again, ', 'she stepped out and i stepped in again, ', 'learning new steps for lanigans ball. ', 'boys were all merry and the girls they were hearty ', 'and danced all around in couples and groups, ', 'til an accident happened, young terrance mccarthy ', 'put his right leg through miss finnertys hoops. ', 'poor creature fainted and cried meelia murther, ', 'called for her brothers and gathered them all. ', 'carmody swore that hed go no further ', 'til he had satisfaction at lanigans ball. ', 'in the midst of the row miss kerrigan fainted, ', 'her cheeks at the same time as red as a rose. ', 'some of the lads declared she was painted, ', 'she took a small drop too much, i suppose. ', 'her sweetheart, ned morgan, so powerful and able, ', 'when he saw his fair colleen stretched out by the wall, ', 'tore the left leg from under the table ', 'and smashed all the chaneys at lanigans ball. ', 'boys, oh boys, twas then there were runctions. ', 'myself got a lick from big phelim mchugh. ', 'i soon replied to his introduction ', 'and kicked up a terrible hullabaloo. ', 'old casey, the piper, was near being strangled. ', 'they squeezed up his pipes, bellows, chanters and all. ', 'the girls, in their ribbons, they got all entangled ', 'and that put an end to lanigans ball.']\n"
          ]
        }
      ],
      "source": [
        "data=\"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\nWho didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\nOf the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\nFor all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\nWere dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\nShe tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\nJust in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\nPotatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\nCourting the girls and dancing away. \\nSongs they went round as plenty as water, \\nThe harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\nAll singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\nAll round the room in a whirligig. \\nJulia and I, we banished their nonsense \\nAnd tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\nDanced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\nLearning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\nThree long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\nLearning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\nI stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\nLearning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\nAnd danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\nPut his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\nCalled for her brothers and gathered them all. \\nCarmody swore that hed go no further \\nTil he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\nHer cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\nShe took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\nWhen he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\nAnd smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\nMyself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\nOld Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\nThe girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\"\n",
        "\n",
        "# Split the long string per line and put in a list\n",
        "\n",
        "corpus = data.lower()\n",
        "corpus = corpus.split(\"\\n\")\n",
        "\n",
        "# Preview the result\n",
        "print(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "total_words = len(tokenizer.word_index)+1"
      ],
      "metadata": {
        "id": "MGRpoW4bYr4Q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index) # a dictionary of word/key and index/value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYiCZiPTZoBJ",
        "outputId": "412edc93-dab7-4a08-93a4-7fd428b094dd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "\n",
        "for line in corpus:\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0] # line is a string and text_to_sequence that we applied in the past is on strings inside a list. [0] is to remove the second braket\n",
        "  for i in range(1, len(token_list)):\n",
        "    input_sequences.append(token_list[:i+1])\n",
        "\n",
        "print(input_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEcuLMZsZsFY",
        "outputId": "9583c073-34f0-469d-c8c3-d9768e8febe9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4, 2], [4, 2, 66], [4, 2, 66, 8], [4, 2, 66, 8, 67], [4, 2, 66, 8, 67, 68], [4, 2, 66, 8, 67, 68, 69], [4, 2, 66, 8, 67, 68, 69, 70], [71, 40], [71, 40, 20], [71, 40, 20, 21], [71, 40, 20, 21, 72], [71, 40, 20, 21, 72, 3], [71, 40, 20, 21, 72, 3, 73], [16, 74], [16, 74, 75], [16, 74, 75, 1], [16, 74, 75, 1, 76], [16, 74, 75, 1, 76, 33], [16, 74, 75, 1, 76, 33, 3], [16, 74, 75, 1, 76, 33, 3, 77], [16, 74, 75, 1, 76, 33, 3, 77, 22], [41, 33], [41, 33, 3], [41, 33, 3, 78], [41, 33, 3, 78, 1], [41, 33, 3, 78, 1, 79], [41, 33, 3, 78, 1, 79, 80], [41, 33, 3, 78, 1, 79, 80, 8], [41, 33, 3, 78, 1, 79, 80, 8, 81], [21, 82], [21, 82, 3], [21, 82, 3, 83], [21, 82, 3, 83, 84], [21, 82, 3, 83, 84, 7], [21, 82, 3, 83, 84, 7, 42], [21, 82, 3, 83, 84, 7, 42, 1], [21, 82, 3, 83, 84, 7, 42, 1, 43], [85, 86], [85, 86, 87], [85, 86, 87, 33], [85, 86, 87, 33, 44], [85, 86, 87, 33, 44, 88], [85, 86, 87, 33, 44, 88, 13], [85, 86, 87, 33, 44, 88, 13, 2], [85, 86, 87, 33, 44, 88, 13, 2, 45], [1, 89], [1, 89, 90], [1, 89, 90, 91], [1, 89, 90, 91, 92], [1, 89, 90, 91, 92, 93], [1, 89, 90, 91, 92, 93, 94], [1, 89, 90, 91, 92, 93, 94, 95], [1, 89, 90, 91, 92, 93, 94, 95, 96], [1, 89, 90, 91, 92, 93, 94, 95, 96, 97], [8, 2], [8, 2, 98], [8, 2, 98, 1], [8, 2, 98, 1, 2], [8, 2, 98, 1, 2, 99], [8, 2, 98, 1, 2, 99, 8], [8, 2, 98, 1, 2, 99, 8, 9], [8, 2, 98, 1, 2, 99, 8, 9, 10], [46, 13], [46, 13, 100], [46, 13, 100, 101], [46, 13, 100, 101, 23], [46, 13, 100, 101, 23, 102], [46, 13, 100, 101, 23, 102, 103], [7, 5], [7, 5, 2], [7, 5, 2, 47], [7, 5, 2, 47, 17], [7, 5, 2, 47, 17, 1], [7, 5, 2, 47, 17, 1, 24], [7, 5, 2, 47, 17, 1, 24, 6], [7, 5, 2, 47, 17, 1, 24, 6, 104], [7, 5, 2, 47, 17, 1, 24, 6, 104, 105], [1, 48], [1, 48, 4], [1, 48, 4, 3], [1, 48, 4, 3, 106], [1, 48, 4, 3, 106, 107], [1, 48, 4, 3, 106, 107, 42], [1, 48, 4, 3, 106, 107, 42, 1], [1, 48, 4, 3, 106, 107, 42, 1, 43], [11, 49], [11, 49, 25], [11, 49, 25, 50], [11, 49, 25, 50, 18], [11, 49, 25, 50, 18, 108], [11, 49, 25, 50, 18, 108, 25], [11, 49, 25, 50, 18, 108, 25, 3], [11, 49, 25, 50, 18, 108, 25, 3, 109], [110, 111], [110, 111, 26], [110, 111, 26, 47], [110, 111, 26, 47, 112], [110, 111, 26, 47, 112, 113], [14, 51], [14, 51, 52], [14, 51, 52, 3], [14, 51, 52, 3, 114], [14, 51, 52, 3, 114, 7], [14, 51, 52, 3, 114, 7, 13], [14, 51, 52, 3, 114, 7, 13, 115], [14, 51, 52, 3, 114, 7, 13, 115, 27], [14, 51, 52, 3, 114, 7, 13, 115, 27, 3], [14, 51, 52, 3, 114, 7, 13, 115, 27, 3, 116], [1, 6], [1, 6, 53], [1, 6, 53, 117], [1, 6, 53, 117, 118], [1, 6, 53, 117, 118, 119], [1, 6, 53, 117, 118, 119, 120], [48, 4], [48, 4, 54], [48, 4, 54, 7], [48, 4, 54, 7, 9], [48, 4, 54, 7, 9, 10], [28, 11], [28, 11, 121], [28, 11, 121, 8], [28, 11, 121, 8, 122], [28, 11, 121, 8, 122, 1], [28, 11, 121, 8, 122, 1, 123], [28, 11, 121, 8, 122, 1, 123, 7], [28, 11, 121, 8, 122, 1, 123, 7, 2], [28, 11, 121, 8, 122, 1, 123, 7, 2, 124], [125, 1], [125, 1, 126], [125, 1, 126, 28], [125, 1, 126, 28, 34], [125, 1, 126, 28, 34, 127], [125, 1, 126, 28, 34, 127, 1], [125, 1, 126, 28, 34, 127, 1, 128], [28, 11], [28, 11, 2], [28, 11, 2, 129], [28, 11, 2, 129, 130], [28, 11, 2, 129, 130, 131], [132, 2], [132, 2, 17], [132, 2, 17, 1], [132, 2, 17, 1, 49], [132, 2, 17, 1, 49, 40], [133, 19], [133, 19, 134], [133, 19, 134, 25], [133, 19, 134, 25, 18], [133, 19, 134, 25, 18, 135], [133, 19, 134, 25, 18, 135, 18], [133, 19, 134, 25, 18, 135, 18, 136], [2, 137], [2, 137, 26], [2, 137, 26, 138], [2, 137, 26, 138, 139], [2, 137, 26, 138, 139, 4], [2, 137, 26, 138, 139, 4, 140], [2, 137, 26, 138, 139, 4, 140, 55], [2, 137, 26, 138, 139, 4, 140, 55, 141], [142, 143], [142, 143, 144], [142, 143, 144, 1], [142, 143, 144, 1, 2], [142, 143, 144, 1, 2, 145], [142, 143, 144, 1, 2, 145, 146], [142, 143, 144, 1, 2, 145, 146, 147], [5, 148], [5, 148, 149], [5, 148, 149, 12], [5, 148, 149, 12, 9], [5, 148, 149, 12, 9, 10], [19, 11], [19, 11, 150], [19, 11, 150, 5], [19, 11, 150, 5, 151], [19, 11, 150, 5, 151, 8], [19, 11, 150, 5, 151, 8, 152], [19, 11, 150, 5, 151, 8, 152, 153], [5, 25], [5, 25, 2], [5, 25, 2, 154], [5, 25, 2, 154, 4], [5, 25, 2, 154, 4, 3], [5, 25, 2, 154, 4, 3, 155], [156, 1], [156, 1, 6], [156, 1, 6, 157], [156, 1, 6, 157, 158], [156, 1, 6, 157, 158, 56], [156, 1, 6, 157, 158, 56, 159], [1, 51], [1, 51, 57], [1, 51, 57, 2], [1, 51, 57, 2, 160], [1, 51, 57, 2, 160, 8], [1, 51, 57, 2, 160, 8, 3], [1, 51, 57, 2, 160, 8, 3, 161], [1, 51, 57, 2, 160, 8, 3, 161, 1], [1, 51, 57, 2, 160, 8, 3, 161, 1, 3], [1, 51, 57, 2, 160, 8, 3, 161, 1, 3, 162], [163, 164], [163, 164, 165], [163, 164, 165, 2], [163, 164, 165, 2, 17], [163, 164, 165, 2, 17, 23], [163, 164, 165, 2, 17, 23, 5], [163, 164, 165, 2, 17, 23, 5, 166], [163, 164, 165, 2, 17, 23, 5, 166, 12], [163, 164, 165, 2, 17, 23, 5, 166, 12, 52], [58, 20], [58, 20, 167], [58, 20, 167, 168], [58, 20, 167, 168, 2], [58, 20, 167, 168, 2, 169], [58, 20, 167, 168, 2, 169, 170], [58, 20, 167, 168, 2, 169, 170, 171], [7, 6], [7, 6, 35], [7, 6, 35, 29], [7, 6, 35, 29, 30], [7, 6, 35, 29, 30, 12], [7, 6, 35, 29, 30, 12, 172], [7, 6, 35, 29, 30, 12, 172, 173], [36, 37], [36, 37, 38], [36, 37, 38, 7], [36, 37, 38, 7, 9], [36, 37, 38, 7, 9, 10], [29, 39], [29, 39, 30], [29, 39, 30, 6], [29, 39, 30, 6, 35], [29, 39, 30, 6, 35, 31], [29, 39, 30, 6, 35, 31, 4], [29, 39, 30, 6, 35, 31, 4, 59], [29, 39], [29, 39, 30], [29, 39, 30, 13], [29, 39, 30, 13, 174], [29, 39, 30, 13, 174, 175], [29, 39, 30, 13, 174, 175, 12], [29, 39, 30, 13, 174, 175, 12, 5], [29, 39], [29, 39, 30], [29, 39, 30, 6], [29, 39, 30, 6, 35], [29, 39, 30, 6, 35, 31], [29, 39, 30, 6, 35, 31, 4], [29, 39, 30, 6, 35, 31, 4, 59], [36, 37], [36, 37, 38], [36, 37, 38, 7], [36, 37, 38, 7, 9], [36, 37, 38, 7, 9, 10], [14, 15], [14, 15, 32], [14, 15, 32, 1], [14, 15, 32, 1, 6], [14, 15, 32, 1, 6, 15], [14, 15, 32, 1, 6, 15, 4], [14, 15, 32, 1, 6, 15, 4, 22], [6, 15], [6, 15, 32], [6, 15, 32, 1], [6, 15, 32, 1, 14], [6, 15, 32, 1, 14, 15], [6, 15, 32, 1, 14, 15, 4], [6, 15, 32, 1, 14, 15, 4, 22], [14, 15], [14, 15, 32], [14, 15, 32, 1], [14, 15, 32, 1, 6], [14, 15, 32, 1, 6, 15], [14, 15, 32, 1, 6, 15, 4], [14, 15, 32, 1, 6, 15, 4, 22], [36, 37], [36, 37, 38], [36, 37, 38, 7], [36, 37, 38, 7, 9], [36, 37, 38, 7, 9, 10], [24, 11], [24, 11, 5], [24, 11, 5, 50], [24, 11, 5, 50, 1], [24, 11, 5, 50, 1, 2], [24, 11, 5, 50, 1, 2, 17], [24, 11, 5, 50, 1, 2, 17, 19], [24, 11, 5, 50, 1, 2, 17, 19, 11], [24, 11, 5, 50, 1, 2, 17, 19, 11, 176], [1, 58], [1, 58, 5], [1, 58, 5, 177], [1, 58, 5, 177, 4], [1, 58, 5, 177, 4, 178], [1, 58, 5, 177, 4, 178, 1], [1, 58, 5, 177, 4, 178, 1, 179], [20, 60], [20, 60, 180], [20, 60, 180, 181], [20, 60, 180, 181, 182], [20, 60, 180, 181, 182, 183], [20, 60, 180, 181, 182, 183, 184], [61, 16], [61, 16, 185], [61, 16, 185, 62], [61, 16, 185, 62, 186], [61, 16, 185, 62, 186, 63], [61, 16, 185, 62, 186, 63, 187], [61, 16, 185, 62, 186, 63, 187, 188], [189, 190], [189, 190, 64], [189, 190, 64, 1], [189, 190, 64, 1, 191], [189, 190, 64, 1, 191, 192], [189, 190, 64, 1, 191, 192, 193], [194, 7], [194, 7, 27], [194, 7, 27, 195], [194, 7, 27, 195, 1], [194, 7, 27, 195, 1, 196], [194, 7, 27, 195, 1, 196, 57], [194, 7, 27, 195, 1, 196, 57, 5], [197, 198], [197, 198, 26], [197, 198, 26, 199], [197, 198, 26, 199, 200], [197, 198, 26, 199, 200, 201], [197, 198, 26, 199, 200, 201, 202], [20, 21], [20, 21, 203], [20, 21, 203, 204], [20, 21, 203, 204, 12], [20, 21, 203, 204, 12, 9], [20, 21, 203, 204, 12, 9, 10], [4, 2], [4, 2, 205], [4, 2, 205, 8], [4, 2, 205, 8, 2], [4, 2, 205, 8, 2, 206], [4, 2, 205, 8, 2, 206, 63], [4, 2, 205, 8, 2, 206, 63, 207], [4, 2, 205, 8, 2, 206, 63, 207, 64], [27, 208], [27, 208, 12], [27, 208, 12, 2], [27, 208, 12, 2, 209], [27, 208, 12, 2, 209, 54], [27, 208, 12, 2, 209, 54, 18], [27, 208, 12, 2, 209, 54, 18, 210], [27, 208, 12, 2, 209, 54, 18, 210, 18], [27, 208, 12, 2, 209, 54, 18, 210, 18, 3], [27, 208, 12, 2, 209, 54, 18, 210, 18, 3, 211], [212, 8], [212, 8, 2], [212, 8, 2, 213], [212, 8, 2, 213, 214], [212, 8, 2, 213, 214, 14], [212, 8, 2, 213, 214, 14, 34], [212, 8, 2, 213, 214, 14, 34, 215], [14, 216], [14, 216, 3], [14, 216, 3, 217], [14, 216, 3, 217, 218], [14, 216, 3, 217, 218, 219], [14, 216, 3, 217, 218, 219, 220], [14, 216, 3, 217, 218, 219, 220, 6], [14, 216, 3, 217, 218, 219, 220, 6, 221], [27, 222], [27, 222, 223], [27, 222, 223, 224], [27, 222, 223, 224, 225], [27, 222, 223, 224, 225, 226], [27, 222, 223, 224, 225, 226, 1], [27, 222, 223, 224, 225, 226, 1, 227], [44, 21], [44, 21, 228], [44, 21, 228, 16], [44, 21, 228, 16, 229], [44, 21, 228, 16, 229, 230], [44, 21, 228, 16, 229, 230, 231], [44, 21, 228, 16, 229, 230, 231, 32], [44, 21, 228, 16, 229, 230, 231, 32, 232], [44, 21, 228, 16, 229, 230, 231, 32, 232, 2], [44, 21, 228, 16, 229, 230, 231, 32, 232, 2, 45], [233, 2], [233, 2, 41], [233, 2, 41, 62], [233, 2, 41, 62, 65], [233, 2, 41, 62, 65, 234], [233, 2, 41, 62, 65, 234, 2], [233, 2, 41, 62, 65, 234, 2, 235], [1, 236], [1, 236, 5], [1, 236, 5, 2], [1, 236, 5, 2, 237], [1, 236, 5, 2, 237, 12], [1, 236, 5, 2, 237, 12, 9], [1, 236, 5, 2, 237, 12, 9, 10], [24, 238], [24, 238, 24], [24, 238, 24, 239], [24, 238, 24, 239, 240], [24, 238, 24, 239, 240, 28], [24, 238, 24, 239, 240, 28, 11], [24, 238, 24, 239, 240, 28, 11, 241], [46, 23], [46, 23, 3], [46, 23, 3, 242], [46, 23, 3, 242, 65], [46, 23, 3, 242, 65, 243], [46, 23, 3, 242, 65, 243, 244], [46, 23, 3, 242, 65, 243, 244, 245], [6, 53], [6, 53, 246], [6, 53, 246, 13], [6, 53, 246, 13, 16], [6, 53, 246, 13, 16, 247], [1, 248], [1, 248, 31], [1, 248, 31, 3], [1, 248, 31, 3, 249], [1, 248, 31, 3, 249, 250], [55, 251], [55, 251, 2], [55, 251, 2, 252], [55, 251, 2, 252, 34], [55, 251, 2, 252, 34, 253], [55, 251, 2, 252, 34, 253, 254], [55, 251, 2, 252, 34, 253, 254, 255], [19, 256], [19, 256, 31], [19, 256, 31, 16], [19, 256, 31, 16, 257], [19, 256, 31, 16, 257, 258], [19, 256, 31, 16, 257, 258, 259], [19, 256, 31, 16, 257, 258, 259, 1], [19, 256, 31, 16, 257, 258, 259, 1, 5], [2, 17], [2, 17, 4], [2, 17, 4, 56], [2, 17, 4, 56, 260], [2, 17, 4, 56, 260, 19], [2, 17, 4, 56, 260, 19, 23], [2, 17, 4, 56, 260, 19, 23, 5], [2, 17, 4, 56, 260, 19, 23, 5, 261], [1, 26], [1, 26, 61], [1, 26, 61, 60], [1, 26, 61, 60, 262], [1, 26, 61, 60, 262, 13], [1, 26, 61, 60, 262, 13, 9], [1, 26, 61, 60, 262, 13, 9, 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list = []\n",
        "for x in input_sequences:\n",
        "  list.append(len(x))\n"
      ],
      "metadata": {
        "id": "G08BsoRFauCZ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0k0wLj-dE5S",
        "outputId": "c4fb189d-766a-4a9c-fc8f-b3d1e5140f2a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 7, 8, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 2, 3, 4, 5, 6, 7, 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len = max(list)\n",
        "max_sequence_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BlqNkRaeHXa",
        "outputId": "c2f8c8ba-4619-4f0b-be1c-dea7db233214"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = pad_sequences(input_sequences, maxlen = max_sequence_len, padding = 'pre')\n",
        "\n",
        "print(input_sequences[:10])\n",
        "input_sequences.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP4af-6NeLrg",
        "outputId": "c2803e75-3840-495b-eca7-56d244d63a1f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  0  0  0  0  0  0  0  0  4  2]\n",
            " [ 0  0  0  0  0  0  0  0  4  2 66]\n",
            " [ 0  0  0  0  0  0  0  4  2 66  8]\n",
            " [ 0  0  0  0  0  0  4  2 66  8 67]\n",
            " [ 0  0  0  0  0  4  2 66  8 67 68]\n",
            " [ 0  0  0  0  4  2 66  8 67 68 69]\n",
            " [ 0  0  0  4  2 66  8 67 68 69 70]\n",
            " [ 0  0  0  0  0  0  0  0  0 71 40]\n",
            " [ 0  0  0  0  0  0  0  0 71 40 20]\n",
            " [ 0  0  0  0  0  0  0 71 40 20 21]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(453, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs, labels = input_sequences[:,:-1], input_sequences[:, -1]"
      ],
      "metadata": {
        "id": "AGN48YwNeuZ9"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(xs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucYx2hrBfR8v",
        "outputId": "6015d3cf-6b89-4753-8f84-6f66382ba0f6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0 ...   0   0   4]\n",
            " [  0   0   0 ...   0   4   2]\n",
            " [  0   0   0 ...   4   2  66]\n",
            " ...\n",
            " [  0   0   0 ...  61  60 262]\n",
            " [  0   0   0 ...  60 262  13]\n",
            " [  0   0   0 ... 262  13   9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEs_rVQvfbqV",
        "outputId": "f171a2d0-f283-4d60-ad00-1ac9b0419856"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  2  66   8  67  68  69  70  40  20  21  72   3  73  74  75   1  76  33\n",
            "   3  77  22  33   3  78   1  79  80   8  81  82   3  83  84   7  42   1\n",
            "  43  86  87  33  44  88  13   2  45  89  90  91  92  93  94  95  96  97\n",
            "   2  98   1   2  99   8   9  10  13 100 101  23 102 103   5   2  47  17\n",
            "   1  24   6 104 105  48   4   3 106 107  42   1  43  49  25  50  18 108\n",
            "  25   3 109 111  26  47 112 113  51  52   3 114   7  13 115  27   3 116\n",
            "   6  53 117 118 119 120   4  54   7   9  10  11 121   8 122   1 123   7\n",
            "   2 124   1 126  28  34 127   1 128  11   2 129 130 131   2  17   1  49\n",
            "  40  19 134  25  18 135  18 136 137  26 138 139   4 140  55 141 143 144\n",
            "   1   2 145 146 147 148 149  12   9  10  11 150   5 151   8 152 153  25\n",
            "   2 154   4   3 155   1   6 157 158  56 159  51  57   2 160   8   3 161\n",
            "   1   3 162 164 165   2  17  23   5 166  12  52  20 167 168   2 169 170\n",
            " 171   6  35  29  30  12 172 173  37  38   7   9  10  39  30   6  35  31\n",
            "   4  59  39  30  13 174 175  12   5  39  30   6  35  31   4  59  37  38\n",
            "   7   9  10  15  32   1   6  15   4  22  15  32   1  14  15   4  22  15\n",
            "  32   1   6  15   4  22  37  38   7   9  10  11   5  50   1   2  17  19\n",
            "  11 176  58   5 177   4 178   1 179  60 180 181 182 183 184  16 185  62\n",
            " 186  63 187 188 190  64   1 191 192 193   7  27 195   1 196  57   5 198\n",
            "  26 199 200 201 202  21 203 204  12   9  10   2 205   8   2 206  63 207\n",
            "  64 208  12   2 209  54  18 210  18   3 211   8   2 213 214  14  34 215\n",
            " 216   3 217 218 219 220   6 221 222 223 224 225 226   1 227  21 228  16\n",
            " 229 230 231  32 232   2  45   2  41  62  65 234   2 235 236   5   2 237\n",
            "  12   9  10 238  24 239 240  28  11 241  23   3 242  65 243 244 245  53\n",
            " 246  13  16 247 248  31   3 249 250 251   2 252  34 253 254 255 256  31\n",
            "  16 257 258 259   1   5  17   4  56 260  19  23   5 261  26  61  60 262\n",
            "  13   9  10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs.shape, labels.shape # so there are 453 lines and training data has 2-D array with 1D array of labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ8vsONIfmL5",
        "outputId": "5f0779c8-8e3f-408e-d691-60223eb33bd0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((453, 10), (453,))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the labels into one-hot arrays\n",
        "import tensorflow as tf\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes = total_words)"
      ],
      "metadata": {
        "id": "OcDDRtAafuLM"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ys), len(ys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O_EYNA0gN3N",
        "outputId": "7ee0d886-1c1c-4e6c-f16d-00cfed404299"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 453)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ys.shape, ys[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54vMjYl8inl4",
        "outputId": "2c15c367-0a7f-4dec-8c7d-43e6e4a48538"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((453, 263),\n",
              " array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get sample sentence\n",
        "\n",
        "sentence = corpus[0]"
      ],
      "metadata": {
        "id": "ZPTZwtL9gTpO"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "id": "cfan_6DogpVS",
        "outputId": "b3a7a2b3-62d8-4aaa-a52e-e54534cede1c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'in the town of athy one jeremy lanigan '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = sentence.split()"
      ],
      "metadata": {
        "id": "AZm9Tx9-gqh_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOsULqw2gxZO",
        "outputId": "6989dbf4-276f-4cd8-d2b6-e81cf911dff9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['in', 'the', 'town', 'of', 'athy', 'one', 'jeremy', 'lanigan']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index['in']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8pTvDIthMw5",
        "outputId": "6011adca-caab-4baa-8cb5-c76e8145e8ae"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_list = []\n",
        "\n",
        "for word in sentence:\n",
        "  token_list.append(tokenizer.word_index[word])"
      ],
      "metadata": {
        "id": "-mX8F71zgym_"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(token_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CssDmFPdhTAd",
        "outputId": "b6053e82-2cbc-4aea-83c1-6b4c72da2e95"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4, 2, 66, 8, 67, 68, 69, 70]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs[6], labels[6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd6SGpBshWBu",
        "outputId": "5086620f-7bef-4492-87ce-8f364a66008c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0,  0,  0,  4,  2, 66,  8, 67, 68, 69], dtype=int32), 70)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.sequences_to_texts([xs[6]]) # reverse can be done for texts_to_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WD8BKKkWhdl0",
        "outputId": "25e5eb2a-857c-4e1b-b3e2-51374cba4c81"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['in the town of athy one jeremy']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.argmax(ys[6]) # this returns the index of '1' amoung zeros after one-hot encoded ys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEcaN4H2jptx",
        "outputId": "179200e7-a7b0-4dd5-8a1a-c4c0ea2289a0"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(total_words, 64, input_length=max_sequence_len - 1),   # max_sequence_len - 1 (number of columns in xs/training_data shape)                  \n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n",
        "        tf.keras.layers.Dense(total_words, activation = 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "xY8Jf3nvkLab"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-raJAXKAl7N5",
        "outputId": "9bc82dee-9c14-4511-8b87-aa2fffea721c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 10, 64)            16832     \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 40)               13600     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 263)               10783     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41,215\n",
            "Trainable params: 41,215\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(xs, ys, epochs = 500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4N_vt4RmAEo",
        "outputId": "9860ab5e-f489-4371-a16f-c043e98897aa"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "15/15 [==============================] - 8s 10ms/step - loss: 5.5668 - accuracy: 0.0265\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.5364 - accuracy: 0.0508\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.4535 - accuracy: 0.0508\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 5.2675 - accuracy: 0.0552\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.1160 - accuracy: 0.0508\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.0741 - accuracy: 0.0508\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 5.0468 - accuracy: 0.0486\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 5.0224 - accuracy: 0.0552\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.9968 - accuracy: 0.0596\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.9712 - accuracy: 0.0486\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.9418 - accuracy: 0.0574\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.9065 - accuracy: 0.0684\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.8718 - accuracy: 0.0728\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.8332 - accuracy: 0.0530\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.7880 - accuracy: 0.0530\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.7368 - accuracy: 0.0552\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.6820 - accuracy: 0.0839\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.6322 - accuracy: 0.0861\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.5748 - accuracy: 0.0817\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.5202 - accuracy: 0.0861\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.4623 - accuracy: 0.0927\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.4117 - accuracy: 0.1082\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.3597 - accuracy: 0.1060\n",
            "Epoch 24/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.3108 - accuracy: 0.1082\n",
            "Epoch 25/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.2727 - accuracy: 0.1214\n",
            "Epoch 26/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.2040 - accuracy: 0.1214\n",
            "Epoch 27/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 4.1409 - accuracy: 0.1104\n",
            "Epoch 28/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.0835 - accuracy: 0.1280\n",
            "Epoch 29/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 4.0305 - accuracy: 0.1369\n",
            "Epoch 30/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.9717 - accuracy: 0.1567\n",
            "Epoch 31/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.9082 - accuracy: 0.1589\n",
            "Epoch 32/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.8562 - accuracy: 0.1567\n",
            "Epoch 33/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.8026 - accuracy: 0.1611\n",
            "Epoch 34/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.7552 - accuracy: 0.1898\n",
            "Epoch 35/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.6974 - accuracy: 0.1876\n",
            "Epoch 36/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 3.6507 - accuracy: 0.2340\n",
            "Epoch 37/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.5907 - accuracy: 0.2406\n",
            "Epoch 38/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.5374 - accuracy: 0.2494\n",
            "Epoch 39/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 3.5365 - accuracy: 0.2362\n",
            "Epoch 40/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 3.4979 - accuracy: 0.2384\n",
            "Epoch 41/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 3.4433 - accuracy: 0.2494\n",
            "Epoch 42/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.3906 - accuracy: 0.2914\n",
            "Epoch 43/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.3338 - accuracy: 0.3068\n",
            "Epoch 44/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.2707 - accuracy: 0.3223\n",
            "Epoch 45/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 3.2192 - accuracy: 0.3422\n",
            "Epoch 46/500\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 3.1677 - accuracy: 0.3289\n",
            "Epoch 47/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 3.1197 - accuracy: 0.3510\n",
            "Epoch 48/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.0682 - accuracy: 0.3841\n",
            "Epoch 49/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 3.0247 - accuracy: 0.3797\n",
            "Epoch 50/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.9752 - accuracy: 0.4040\n",
            "Epoch 51/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 2.9297 - accuracy: 0.4260\n",
            "Epoch 52/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.8900 - accuracy: 0.4283\n",
            "Epoch 53/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.8468 - accuracy: 0.4238\n",
            "Epoch 54/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.8047 - accuracy: 0.4393\n",
            "Epoch 55/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.7637 - accuracy: 0.4459\n",
            "Epoch 56/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.7389 - accuracy: 0.4547\n",
            "Epoch 57/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 2.7197 - accuracy: 0.4437\n",
            "Epoch 58/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.6728 - accuracy: 0.4636\n",
            "Epoch 59/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.6348 - accuracy: 0.4746\n",
            "Epoch 60/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.5992 - accuracy: 0.4724\n",
            "Epoch 61/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.5537 - accuracy: 0.4857\n",
            "Epoch 62/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.5198 - accuracy: 0.4967\n",
            "Epoch 63/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 2.4867 - accuracy: 0.5099\n",
            "Epoch 64/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.4562 - accuracy: 0.5188\n",
            "Epoch 65/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.4166 - accuracy: 0.5166\n",
            "Epoch 66/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.3716 - accuracy: 0.5408\n",
            "Epoch 67/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.3380 - accuracy: 0.5386\n",
            "Epoch 68/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.3021 - accuracy: 0.5453\n",
            "Epoch 69/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.2670 - accuracy: 0.5563\n",
            "Epoch 70/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 2.2368 - accuracy: 0.5695\n",
            "Epoch 71/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.2009 - accuracy: 0.5806\n",
            "Epoch 72/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.1782 - accuracy: 0.5828\n",
            "Epoch 73/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.1506 - accuracy: 0.6049\n",
            "Epoch 74/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.1224 - accuracy: 0.5960\n",
            "Epoch 75/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.0976 - accuracy: 0.6049\n",
            "Epoch 76/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.0730 - accuracy: 0.6181\n",
            "Epoch 77/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.0457 - accuracy: 0.6225\n",
            "Epoch 78/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.0277 - accuracy: 0.6269\n",
            "Epoch 79/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.0205 - accuracy: 0.6336\n",
            "Epoch 80/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.9797 - accuracy: 0.6468\n",
            "Epoch 81/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.9675 - accuracy: 0.6623\n",
            "Epoch 82/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.9437 - accuracy: 0.6490\n",
            "Epoch 83/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.9078 - accuracy: 0.6424\n",
            "Epoch 84/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.8742 - accuracy: 0.6556\n",
            "Epoch 85/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.8434 - accuracy: 0.6667\n",
            "Epoch 86/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.8131 - accuracy: 0.6733\n",
            "Epoch 87/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.7947 - accuracy: 0.6711\n",
            "Epoch 88/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.7638 - accuracy: 0.6887\n",
            "Epoch 89/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.7464 - accuracy: 0.7020\n",
            "Epoch 90/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.7270 - accuracy: 0.6909\n",
            "Epoch 91/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.6926 - accuracy: 0.7108\n",
            "Epoch 92/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.6658 - accuracy: 0.7130\n",
            "Epoch 93/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.6444 - accuracy: 0.7196\n",
            "Epoch 94/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.6267 - accuracy: 0.7307\n",
            "Epoch 95/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.6315 - accuracy: 0.7196\n",
            "Epoch 96/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 1.6405 - accuracy: 0.7086\n",
            "Epoch 97/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.5965 - accuracy: 0.7373\n",
            "Epoch 98/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.5775 - accuracy: 0.7285\n",
            "Epoch 99/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.5504 - accuracy: 0.7329\n",
            "Epoch 100/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.5232 - accuracy: 0.7373\n",
            "Epoch 101/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.5005 - accuracy: 0.7439\n",
            "Epoch 102/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.4760 - accuracy: 0.7483\n",
            "Epoch 103/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.4592 - accuracy: 0.7506\n",
            "Epoch 104/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.4556 - accuracy: 0.7506\n",
            "Epoch 105/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.4366 - accuracy: 0.7594\n",
            "Epoch 106/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.4232 - accuracy: 0.7638\n",
            "Epoch 107/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3947 - accuracy: 0.7682\n",
            "Epoch 108/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3679 - accuracy: 0.7726\n",
            "Epoch 109/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3497 - accuracy: 0.7881\n",
            "Epoch 110/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3310 - accuracy: 0.7859\n",
            "Epoch 111/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3093 - accuracy: 0.7903\n",
            "Epoch 112/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3164 - accuracy: 0.7815\n",
            "Epoch 113/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.3012 - accuracy: 0.7881\n",
            "Epoch 114/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.2792 - accuracy: 0.7903\n",
            "Epoch 115/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 1.2597 - accuracy: 0.7881\n",
            "Epoch 116/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.2398 - accuracy: 0.7991\n",
            "Epoch 117/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.2206 - accuracy: 0.8013\n",
            "Epoch 118/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.2067 - accuracy: 0.8057\n",
            "Epoch 119/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.1893 - accuracy: 0.8102\n",
            "Epoch 120/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.1697 - accuracy: 0.8212\n",
            "Epoch 121/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.1567 - accuracy: 0.8234\n",
            "Epoch 122/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.1420 - accuracy: 0.8234\n",
            "Epoch 123/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.1249 - accuracy: 0.8322\n",
            "Epoch 124/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.1110 - accuracy: 0.8344\n",
            "Epoch 125/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.0962 - accuracy: 0.8411\n",
            "Epoch 126/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.0828 - accuracy: 0.8433\n",
            "Epoch 127/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.0721 - accuracy: 0.8543\n",
            "Epoch 128/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 1.0585 - accuracy: 0.8499\n",
            "Epoch 129/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.0470 - accuracy: 0.8543\n",
            "Epoch 130/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 1.0315 - accuracy: 0.8631\n",
            "Epoch 131/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.0182 - accuracy: 0.8587\n",
            "Epoch 132/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.0059 - accuracy: 0.8698\n",
            "Epoch 133/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.9983 - accuracy: 0.8653\n",
            "Epoch 134/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.9847 - accuracy: 0.8653\n",
            "Epoch 135/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.9959 - accuracy: 0.8631\n",
            "Epoch 136/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.0032 - accuracy: 0.8543\n",
            "Epoch 137/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.0545 - accuracy: 0.8366\n",
            "Epoch 138/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.1294 - accuracy: 0.8124\n",
            "Epoch 139/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.0462 - accuracy: 0.8344\n",
            "Epoch 140/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 1.0165 - accuracy: 0.8256\n",
            "Epoch 141/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.9895 - accuracy: 0.8499\n",
            "Epoch 142/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.9439 - accuracy: 0.8631\n",
            "Epoch 143/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.9169 - accuracy: 0.8764\n",
            "Epoch 144/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8934 - accuracy: 0.8808\n",
            "Epoch 145/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8813 - accuracy: 0.8874\n",
            "Epoch 146/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8654 - accuracy: 0.8896\n",
            "Epoch 147/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8509 - accuracy: 0.8896\n",
            "Epoch 148/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.8400 - accuracy: 0.8896\n",
            "Epoch 149/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.8279 - accuracy: 0.8962\n",
            "Epoch 150/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.8182 - accuracy: 0.8962\n",
            "Epoch 151/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.8080 - accuracy: 0.8962\n",
            "Epoch 152/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.7970 - accuracy: 0.9007\n",
            "Epoch 153/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.7865 - accuracy: 0.8985\n",
            "Epoch 154/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.7784 - accuracy: 0.9007\n",
            "Epoch 155/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.7681 - accuracy: 0.9051\n",
            "Epoch 156/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.7589 - accuracy: 0.9073\n",
            "Epoch 157/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.7521 - accuracy: 0.8985\n",
            "Epoch 158/500\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.7446 - accuracy: 0.9051\n",
            "Epoch 159/500\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.7345 - accuracy: 0.9073\n",
            "Epoch 160/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.7253 - accuracy: 0.9073\n",
            "Epoch 161/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.7163 - accuracy: 0.9117\n",
            "Epoch 162/500\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.7083 - accuracy: 0.9117\n",
            "Epoch 163/500\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.7001 - accuracy: 0.9095\n",
            "Epoch 164/500\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.6927 - accuracy: 0.9139\n",
            "Epoch 165/500\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.6841 - accuracy: 0.9073\n",
            "Epoch 166/500\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.6757 - accuracy: 0.9117\n",
            "Epoch 167/500\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.6684 - accuracy: 0.9139\n",
            "Epoch 168/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.6603 - accuracy: 0.9183\n",
            "Epoch 169/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.6529 - accuracy: 0.9161\n",
            "Epoch 170/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.6457 - accuracy: 0.9161\n",
            "Epoch 171/500\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.6384 - accuracy: 0.9183\n",
            "Epoch 172/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.6311 - accuracy: 0.9205\n",
            "Epoch 173/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.6238 - accuracy: 0.9205\n",
            "Epoch 174/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.6175 - accuracy: 0.9161\n",
            "Epoch 175/500\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.6099 - accuracy: 0.9161\n",
            "Epoch 176/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.6033 - accuracy: 0.9205\n",
            "Epoch 177/500\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.5959 - accuracy: 0.9227\n",
            "Epoch 178/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.5897 - accuracy: 0.9249\n",
            "Epoch 179/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.5839 - accuracy: 0.9227\n",
            "Epoch 180/500\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.5783 - accuracy: 0.9249\n",
            "Epoch 181/500\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.5716 - accuracy: 0.9294\n",
            "Epoch 182/500\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.5679 - accuracy: 0.9316\n",
            "Epoch 183/500\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.5601 - accuracy: 0.9338\n",
            "Epoch 184/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.5541 - accuracy: 0.9338\n",
            "Epoch 185/500\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.5475 - accuracy: 0.9316\n",
            "Epoch 186/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.5416 - accuracy: 0.9360\n",
            "Epoch 187/500\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.5361 - accuracy: 0.9294\n",
            "Epoch 188/500\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.5304 - accuracy: 0.9360\n",
            "Epoch 189/500\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.5260 - accuracy: 0.9360\n",
            "Epoch 190/500\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.5206 - accuracy: 0.9382\n",
            "Epoch 191/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 0.5151 - accuracy: 0.9382\n",
            "Epoch 192/500\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.5103 - accuracy: 0.9382\n",
            "Epoch 193/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.5080 - accuracy: 0.9382\n",
            "Epoch 194/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.4999 - accuracy: 0.9382\n",
            "Epoch 195/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.4980 - accuracy: 0.9360\n",
            "Epoch 196/500\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.4959 - accuracy: 0.9338\n",
            "Epoch 197/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.4875 - accuracy: 0.9404\n",
            "Epoch 198/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.4816 - accuracy: 0.9404\n",
            "Epoch 199/500\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.4770 - accuracy: 0.9316\n",
            "Epoch 200/500\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.4719 - accuracy: 0.9338\n",
            "Epoch 201/500\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 0.4677 - accuracy: 0.9382\n",
            "Epoch 202/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.4618 - accuracy: 0.9426\n",
            "Epoch 203/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 0.4584 - accuracy: 0.9426\n",
            "Epoch 204/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.4558 - accuracy: 0.9404\n",
            "Epoch 205/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.4540 - accuracy: 0.9382\n",
            "Epoch 206/500\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.4537 - accuracy: 0.9426\n",
            "Epoch 207/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.4526 - accuracy: 0.9404\n",
            "Epoch 208/500\n",
            "15/15 [==============================] - 0s 20ms/step - loss: 0.4575 - accuracy: 0.9360\n",
            "Epoch 209/500\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 0.4907 - accuracy: 0.9294\n",
            "Epoch 210/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.4937 - accuracy: 0.9338\n",
            "Epoch 211/500\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.5151 - accuracy: 0.9272\n",
            "Epoch 212/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.4876 - accuracy: 0.9227\n",
            "Epoch 213/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.4749 - accuracy: 0.9426\n",
            "Epoch 214/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.4631 - accuracy: 0.9382\n",
            "Epoch 215/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.4598 - accuracy: 0.9404\n",
            "Epoch 216/500\n",
            "15/15 [==============================] - 0s 21ms/step - loss: 0.4488 - accuracy: 0.9360\n",
            "Epoch 217/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 0.4370 - accuracy: 0.9382\n",
            "Epoch 218/500\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 0.4270 - accuracy: 0.9426\n",
            "Epoch 219/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.4139 - accuracy: 0.9404\n",
            "Epoch 220/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4062 - accuracy: 0.9404\n",
            "Epoch 221/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3979 - accuracy: 0.9426\n",
            "Epoch 222/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3928 - accuracy: 0.9404\n",
            "Epoch 223/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3971 - accuracy: 0.9426\n",
            "Epoch 224/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3892 - accuracy: 0.9426\n",
            "Epoch 225/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3914 - accuracy: 0.9426\n",
            "Epoch 226/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4014 - accuracy: 0.9360\n",
            "Epoch 227/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3893 - accuracy: 0.9426\n",
            "Epoch 228/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3753 - accuracy: 0.9470\n",
            "Epoch 229/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3719 - accuracy: 0.9426\n",
            "Epoch 230/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3681 - accuracy: 0.9382\n",
            "Epoch 231/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3614 - accuracy: 0.9470\n",
            "Epoch 232/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3589 - accuracy: 0.9426\n",
            "Epoch 233/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3578 - accuracy: 0.9426\n",
            "Epoch 234/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.3542 - accuracy: 0.9448\n",
            "Epoch 235/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3560 - accuracy: 0.9470\n",
            "Epoch 236/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3509 - accuracy: 0.9470\n",
            "Epoch 237/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3550 - accuracy: 0.9426\n",
            "Epoch 238/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3464 - accuracy: 0.9470\n",
            "Epoch 239/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3396 - accuracy: 0.9492\n",
            "Epoch 240/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3370 - accuracy: 0.9492\n",
            "Epoch 241/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3332 - accuracy: 0.9492\n",
            "Epoch 242/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3268 - accuracy: 0.9448\n",
            "Epoch 243/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3247 - accuracy: 0.9492\n",
            "Epoch 244/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3255 - accuracy: 0.9470\n",
            "Epoch 245/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3208 - accuracy: 0.9492\n",
            "Epoch 246/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3190 - accuracy: 0.9470\n",
            "Epoch 247/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3151 - accuracy: 0.9470\n",
            "Epoch 248/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3127 - accuracy: 0.9470\n",
            "Epoch 249/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3083 - accuracy: 0.9470\n",
            "Epoch 250/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3051 - accuracy: 0.9470\n",
            "Epoch 251/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3036 - accuracy: 0.9426\n",
            "Epoch 252/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3012 - accuracy: 0.9448\n",
            "Epoch 253/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2991 - accuracy: 0.9470\n",
            "Epoch 254/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2967 - accuracy: 0.9426\n",
            "Epoch 255/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2940 - accuracy: 0.9492\n",
            "Epoch 256/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2919 - accuracy: 0.9492\n",
            "Epoch 257/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2886 - accuracy: 0.9492\n",
            "Epoch 258/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2864 - accuracy: 0.9492\n",
            "Epoch 259/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2843 - accuracy: 0.9514\n",
            "Epoch 260/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2824 - accuracy: 0.9470\n",
            "Epoch 261/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2803 - accuracy: 0.9492\n",
            "Epoch 262/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2775 - accuracy: 0.9470\n",
            "Epoch 263/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2801 - accuracy: 0.9470\n",
            "Epoch 264/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2738 - accuracy: 0.9514\n",
            "Epoch 265/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2724 - accuracy: 0.9514\n",
            "Epoch 266/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2716 - accuracy: 0.9492\n",
            "Epoch 267/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.2698 - accuracy: 0.9514\n",
            "Epoch 268/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2670 - accuracy: 0.9492\n",
            "Epoch 269/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2647 - accuracy: 0.9514\n",
            "Epoch 270/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2631 - accuracy: 0.9492\n",
            "Epoch 271/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2610 - accuracy: 0.9470\n",
            "Epoch 272/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2586 - accuracy: 0.9448\n",
            "Epoch 273/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2571 - accuracy: 0.9492\n",
            "Epoch 274/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2559 - accuracy: 0.9514\n",
            "Epoch 275/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2558 - accuracy: 0.9448\n",
            "Epoch 276/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2812 - accuracy: 0.9404\n",
            "Epoch 277/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3352 - accuracy: 0.9294\n",
            "Epoch 278/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3798 - accuracy: 0.9205\n",
            "Epoch 279/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4172 - accuracy: 0.9095\n",
            "Epoch 280/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4062 - accuracy: 0.9051\n",
            "Epoch 281/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.4160 - accuracy: 0.8985\n",
            "Epoch 282/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3784 - accuracy: 0.9161\n",
            "Epoch 283/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3587 - accuracy: 0.9272\n",
            "Epoch 284/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3490 - accuracy: 0.9294\n",
            "Epoch 285/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3411 - accuracy: 0.9294\n",
            "Epoch 286/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3497 - accuracy: 0.9249\n",
            "Epoch 287/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.3090 - accuracy: 0.9360\n",
            "Epoch 288/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2932 - accuracy: 0.9382\n",
            "Epoch 289/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2806 - accuracy: 0.9448\n",
            "Epoch 290/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2763 - accuracy: 0.9448\n",
            "Epoch 291/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2632 - accuracy: 0.9492\n",
            "Epoch 292/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2544 - accuracy: 0.9470\n",
            "Epoch 293/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2487 - accuracy: 0.9492\n",
            "Epoch 294/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2428 - accuracy: 0.9448\n",
            "Epoch 295/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2409 - accuracy: 0.9470\n",
            "Epoch 296/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2371 - accuracy: 0.9448\n",
            "Epoch 297/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2335 - accuracy: 0.9448\n",
            "Epoch 298/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2317 - accuracy: 0.9492\n",
            "Epoch 299/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2269 - accuracy: 0.9470\n",
            "Epoch 300/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2260 - accuracy: 0.9492\n",
            "Epoch 301/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2238 - accuracy: 0.9492\n",
            "Epoch 302/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2211 - accuracy: 0.9514\n",
            "Epoch 303/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2195 - accuracy: 0.9492\n",
            "Epoch 304/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2171 - accuracy: 0.9514\n",
            "Epoch 305/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2157 - accuracy: 0.9470\n",
            "Epoch 306/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2134 - accuracy: 0.9514\n",
            "Epoch 307/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2131 - accuracy: 0.9470\n",
            "Epoch 308/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2126 - accuracy: 0.9470\n",
            "Epoch 309/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2103 - accuracy: 0.9470\n",
            "Epoch 310/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2084 - accuracy: 0.9470\n",
            "Epoch 311/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2068 - accuracy: 0.9492\n",
            "Epoch 312/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2058 - accuracy: 0.9514\n",
            "Epoch 313/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2048 - accuracy: 0.9514\n",
            "Epoch 314/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2040 - accuracy: 0.9448\n",
            "Epoch 315/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2027 - accuracy: 0.9492\n",
            "Epoch 316/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2005 - accuracy: 0.9536\n",
            "Epoch 317/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1989 - accuracy: 0.9514\n",
            "Epoch 318/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1984 - accuracy: 0.9514\n",
            "Epoch 319/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1976 - accuracy: 0.9470\n",
            "Epoch 320/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1956 - accuracy: 0.9536\n",
            "Epoch 321/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1950 - accuracy: 0.9448\n",
            "Epoch 322/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1936 - accuracy: 0.9536\n",
            "Epoch 323/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1923 - accuracy: 0.9492\n",
            "Epoch 324/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1911 - accuracy: 0.9492\n",
            "Epoch 325/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1908 - accuracy: 0.9470\n",
            "Epoch 326/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1891 - accuracy: 0.9536\n",
            "Epoch 327/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1891 - accuracy: 0.9470\n",
            "Epoch 328/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1883 - accuracy: 0.9514\n",
            "Epoch 329/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.1864 - accuracy: 0.9514\n",
            "Epoch 330/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1854 - accuracy: 0.9492\n",
            "Epoch 331/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1846 - accuracy: 0.9492\n",
            "Epoch 332/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1832 - accuracy: 0.9514\n",
            "Epoch 333/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1829 - accuracy: 0.9426\n",
            "Epoch 334/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1816 - accuracy: 0.9470\n",
            "Epoch 335/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1820 - accuracy: 0.9514\n",
            "Epoch 336/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1806 - accuracy: 0.9536\n",
            "Epoch 337/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1789 - accuracy: 0.9492\n",
            "Epoch 338/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1780 - accuracy: 0.9536\n",
            "Epoch 339/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1770 - accuracy: 0.9514\n",
            "Epoch 340/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1756 - accuracy: 0.9492\n",
            "Epoch 341/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1755 - accuracy: 0.9492\n",
            "Epoch 342/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1756 - accuracy: 0.9536\n",
            "Epoch 343/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1749 - accuracy: 0.9514\n",
            "Epoch 344/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1733 - accuracy: 0.9514\n",
            "Epoch 345/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1727 - accuracy: 0.9492\n",
            "Epoch 346/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1726 - accuracy: 0.9470\n",
            "Epoch 347/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1711 - accuracy: 0.9470\n",
            "Epoch 348/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1702 - accuracy: 0.9492\n",
            "Epoch 349/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1697 - accuracy: 0.9514\n",
            "Epoch 350/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1684 - accuracy: 0.9492\n",
            "Epoch 351/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1680 - accuracy: 0.9514\n",
            "Epoch 352/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 0.1677 - accuracy: 0.9470\n",
            "Epoch 353/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1673 - accuracy: 0.9470\n",
            "Epoch 354/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1658 - accuracy: 0.9514\n",
            "Epoch 355/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1650 - accuracy: 0.9492\n",
            "Epoch 356/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1646 - accuracy: 0.9514\n",
            "Epoch 357/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1635 - accuracy: 0.9514\n",
            "Epoch 358/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1634 - accuracy: 0.9492\n",
            "Epoch 359/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1627 - accuracy: 0.9514\n",
            "Epoch 360/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1617 - accuracy: 0.9514\n",
            "Epoch 361/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1611 - accuracy: 0.9514\n",
            "Epoch 362/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1610 - accuracy: 0.9470\n",
            "Epoch 363/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1605 - accuracy: 0.9514\n",
            "Epoch 364/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1594 - accuracy: 0.9514\n",
            "Epoch 365/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1585 - accuracy: 0.9492\n",
            "Epoch 366/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1580 - accuracy: 0.9470\n",
            "Epoch 367/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1569 - accuracy: 0.9492\n",
            "Epoch 368/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1568 - accuracy: 0.9492\n",
            "Epoch 369/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1563 - accuracy: 0.9514\n",
            "Epoch 370/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1556 - accuracy: 0.9536\n",
            "Epoch 371/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1554 - accuracy: 0.9514\n",
            "Epoch 372/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1541 - accuracy: 0.9536\n",
            "Epoch 373/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1540 - accuracy: 0.9536\n",
            "Epoch 374/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1536 - accuracy: 0.9514\n",
            "Epoch 375/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1533 - accuracy: 0.9514\n",
            "Epoch 376/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1523 - accuracy: 0.9536\n",
            "Epoch 377/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1520 - accuracy: 0.9514\n",
            "Epoch 378/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1540 - accuracy: 0.9536\n",
            "Epoch 379/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1518 - accuracy: 0.9514\n",
            "Epoch 380/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1503 - accuracy: 0.9470\n",
            "Epoch 381/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1502 - accuracy: 0.9426\n",
            "Epoch 382/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1490 - accuracy: 0.9382\n",
            "Epoch 383/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1484 - accuracy: 0.9448\n",
            "Epoch 384/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1475 - accuracy: 0.9536\n",
            "Epoch 385/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1468 - accuracy: 0.9470\n",
            "Epoch 386/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1468 - accuracy: 0.9514\n",
            "Epoch 387/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1462 - accuracy: 0.9404\n",
            "Epoch 388/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1452 - accuracy: 0.9492\n",
            "Epoch 389/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1451 - accuracy: 0.9470\n",
            "Epoch 390/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1463 - accuracy: 0.9514\n",
            "Epoch 391/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1448 - accuracy: 0.9492\n",
            "Epoch 392/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1442 - accuracy: 0.9492\n",
            "Epoch 393/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1441 - accuracy: 0.9448\n",
            "Epoch 394/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.1435 - accuracy: 0.9536\n",
            "Epoch 395/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1424 - accuracy: 0.9536\n",
            "Epoch 396/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1420 - accuracy: 0.9492\n",
            "Epoch 397/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1419 - accuracy: 0.9514\n",
            "Epoch 398/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1414 - accuracy: 0.9514\n",
            "Epoch 399/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1410 - accuracy: 0.9514\n",
            "Epoch 400/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1408 - accuracy: 0.9470\n",
            "Epoch 401/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1400 - accuracy: 0.9492\n",
            "Epoch 402/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1393 - accuracy: 0.9470\n",
            "Epoch 403/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1391 - accuracy: 0.9514\n",
            "Epoch 404/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1388 - accuracy: 0.9492\n",
            "Epoch 405/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1388 - accuracy: 0.9536\n",
            "Epoch 406/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1383 - accuracy: 0.9514\n",
            "Epoch 407/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1372 - accuracy: 0.9492\n",
            "Epoch 408/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1368 - accuracy: 0.9492\n",
            "Epoch 409/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1364 - accuracy: 0.9470\n",
            "Epoch 410/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1364 - accuracy: 0.9426\n",
            "Epoch 411/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1359 - accuracy: 0.9426\n",
            "Epoch 412/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1350 - accuracy: 0.9470\n",
            "Epoch 413/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1344 - accuracy: 0.9470\n",
            "Epoch 414/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1337 - accuracy: 0.9470\n",
            "Epoch 415/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1340 - accuracy: 0.9492\n",
            "Epoch 416/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1346 - accuracy: 0.9492\n",
            "Epoch 417/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1345 - accuracy: 0.9514\n",
            "Epoch 418/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1334 - accuracy: 0.9470\n",
            "Epoch 419/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1331 - accuracy: 0.9448\n",
            "Epoch 420/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1320 - accuracy: 0.9514\n",
            "Epoch 421/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1318 - accuracy: 0.9448\n",
            "Epoch 422/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1317 - accuracy: 0.9470\n",
            "Epoch 423/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1338 - accuracy: 0.9514\n",
            "Epoch 424/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.1329 - accuracy: 0.9492\n",
            "Epoch 425/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1319 - accuracy: 0.9492\n",
            "Epoch 426/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1318 - accuracy: 0.9514\n",
            "Epoch 427/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1312 - accuracy: 0.9470\n",
            "Epoch 428/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1301 - accuracy: 0.9492\n",
            "Epoch 429/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1293 - accuracy: 0.9514\n",
            "Epoch 430/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1293 - accuracy: 0.9514\n",
            "Epoch 431/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1288 - accuracy: 0.9492\n",
            "Epoch 432/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1294 - accuracy: 0.9448\n",
            "Epoch 433/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1295 - accuracy: 0.9492\n",
            "Epoch 434/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1280 - accuracy: 0.9536\n",
            "Epoch 435/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1345 - accuracy: 0.9492\n",
            "Epoch 436/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1643 - accuracy: 0.9492\n",
            "Epoch 437/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1559 - accuracy: 0.9448\n",
            "Epoch 438/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1553 - accuracy: 0.9514\n",
            "Epoch 439/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1674 - accuracy: 0.9426\n",
            "Epoch 440/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1588 - accuracy: 0.9404\n",
            "Epoch 441/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1478 - accuracy: 0.9492\n",
            "Epoch 442/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1350 - accuracy: 0.9492\n",
            "Epoch 443/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1440 - accuracy: 0.9514\n",
            "Epoch 444/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1592 - accuracy: 0.9404\n",
            "Epoch 445/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2059 - accuracy: 0.9227\n",
            "Epoch 446/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.2053 - accuracy: 0.9294\n",
            "Epoch 447/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.2247 - accuracy: 0.9338\n",
            "Epoch 448/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1984 - accuracy: 0.9360\n",
            "Epoch 449/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1807 - accuracy: 0.9316\n",
            "Epoch 450/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1715 - accuracy: 0.9382\n",
            "Epoch 451/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1628 - accuracy: 0.9448\n",
            "Epoch 452/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1609 - accuracy: 0.9426\n",
            "Epoch 453/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.1582 - accuracy: 0.9382\n",
            "Epoch 454/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1431 - accuracy: 0.9492\n",
            "Epoch 455/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1371 - accuracy: 0.9492\n",
            "Epoch 456/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1339 - accuracy: 0.9492\n",
            "Epoch 457/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1353 - accuracy: 0.9514\n",
            "Epoch 458/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1313 - accuracy: 0.9536\n",
            "Epoch 459/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1296 - accuracy: 0.9514\n",
            "Epoch 460/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1279 - accuracy: 0.9514\n",
            "Epoch 461/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1275 - accuracy: 0.9514\n",
            "Epoch 462/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1302 - accuracy: 0.9492\n",
            "Epoch 463/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1252 - accuracy: 0.9514\n",
            "Epoch 464/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1235 - accuracy: 0.9470\n",
            "Epoch 465/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1227 - accuracy: 0.9470\n",
            "Epoch 466/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1220 - accuracy: 0.9470\n",
            "Epoch 467/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1217 - accuracy: 0.9448\n",
            "Epoch 468/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1212 - accuracy: 0.9448\n",
            "Epoch 469/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.1207 - accuracy: 0.9470\n",
            "Epoch 470/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1206 - accuracy: 0.9492\n",
            "Epoch 471/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1202 - accuracy: 0.9492\n",
            "Epoch 472/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1204 - accuracy: 0.9492\n",
            "Epoch 473/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1196 - accuracy: 0.9448\n",
            "Epoch 474/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1190 - accuracy: 0.9536\n",
            "Epoch 475/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1209 - accuracy: 0.9536\n",
            "Epoch 476/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1201 - accuracy: 0.9514\n",
            "Epoch 477/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1194 - accuracy: 0.9514\n",
            "Epoch 478/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1183 - accuracy: 0.9470\n",
            "Epoch 479/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1179 - accuracy: 0.9514\n",
            "Epoch 480/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1173 - accuracy: 0.9514\n",
            "Epoch 481/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1170 - accuracy: 0.9492\n",
            "Epoch 482/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1170 - accuracy: 0.9492\n",
            "Epoch 483/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1166 - accuracy: 0.9514\n",
            "Epoch 484/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1163 - accuracy: 0.9514\n",
            "Epoch 485/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1162 - accuracy: 0.9448\n",
            "Epoch 486/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1159 - accuracy: 0.9470\n",
            "Epoch 487/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1162 - accuracy: 0.9514\n",
            "Epoch 488/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1165 - accuracy: 0.9470\n",
            "Epoch 489/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1162 - accuracy: 0.9514\n",
            "Epoch 490/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1154 - accuracy: 0.9492\n",
            "Epoch 491/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 0.1153 - accuracy: 0.9448\n",
            "Epoch 492/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1148 - accuracy: 0.9492\n",
            "Epoch 493/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1142 - accuracy: 0.9492\n",
            "Epoch 494/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1142 - accuracy: 0.9470\n",
            "Epoch 495/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1138 - accuracy: 0.9492\n",
            "Epoch 496/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1141 - accuracy: 0.9448\n",
            "Epoch 497/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1137 - accuracy: 0.9448\n",
            "Epoch 498/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 0.1135 - accuracy: 0.9404\n",
            "Epoch 499/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1131 - accuracy: 0.9448\n",
            "Epoch 500/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 0.1130 - accuracy: 0.9492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot utility\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "# Visualize the accuracy\n",
        "plot_graphs(history, 'accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "sOvN85GgmHn6",
        "outputId": "c337bb9d-55d4-448a-ee56-5302e75dee6a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make your song\n",
        "\n",
        "seed_text = 'Ankur went to Dublin'\n",
        "\n",
        "next_words = 100\n",
        "\n",
        "for _ in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "  token_list = pad_sequences([token_list], maxlen = max_sequence_len-1, padding = 'pre') # here max_sequence_len-1 because we want only 10 columns in test data as we did in train data 'xs'\n",
        "\n",
        "print(token_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQ_WqXxmmgAN",
        "outputId": "220c7f6d-96a4-4ebe-9315-0b6f5cac60c6"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0 134  13  59]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(next_words):\n",
        "  probabilities = model.predict(token_list)"
      ],
      "metadata": {
        "id": "diCtPOhJnfHA"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(probabilities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mtsxVU5ojfa",
        "outputId": "47ed98ff-3350-4cec-876f-58b1180f2c43"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.71288590e-07 2.30266410e-03 3.80367227e-02 1.55843934e-03\n",
            "  7.28735477e-02 3.37145627e-02 1.12664049e-04 1.65208286e-04\n",
            "  1.25453575e-02 4.02644830e-04 5.83734327e-05 1.55668296e-02\n",
            "  9.13469493e-03 1.06760638e-03 5.94361481e-05 1.54646710e-04\n",
            "  4.72137965e-02 3.64019535e-02 2.07407531e-04 2.86873907e-01\n",
            "  8.86890863e-04 1.79065228e-03 1.13329797e-05 1.73721332e-02\n",
            "  9.65832351e-06 2.00570989e-02 2.06054872e-04 1.31880326e-04\n",
            "  2.53618753e-04 4.69056286e-05 7.92044830e-07 2.83046626e-02\n",
            "  6.25236891e-04 2.71836849e-04 1.10630528e-04 9.92929214e-04\n",
            "  9.59362225e-08 1.10075642e-04 4.83364100e-04 2.84863927e-06\n",
            "  1.08923516e-04 1.89138053e-04 6.78369497e-06 3.18612706e-07\n",
            "  4.38333867e-04 2.67602736e-05 1.27838561e-07 3.74822266e-05\n",
            "  3.34234574e-05 1.36016786e-01 4.22696285e-05 5.35524567e-04\n",
            "  5.06220749e-05 6.99658049e-05 5.35807293e-03 2.95927407e-07\n",
            "  2.40262540e-04 5.08824232e-05 3.83900478e-05 2.17760957e-04\n",
            "  6.40245620e-04 8.76307058e-06 1.72202720e-03 7.12608307e-05\n",
            "  6.07963841e-07 4.70199229e-05 1.26914150e-04 4.62355558e-04\n",
            "  5.36771131e-06 2.48623073e-05 3.98105797e-08 1.23416669e-07\n",
            "  3.85903058e-06 2.01952525e-06 2.29706779e-06 1.98776927e-02\n",
            "  1.58672879e-06 1.37834627e-06 3.49144057e-06 9.28377631e-06\n",
            "  5.59713362e-06 2.88740694e-06 2.59631406e-06 2.88763131e-05\n",
            "  1.03146625e-07 1.23778307e-07 2.27495164e-07 1.69510986e-05\n",
            "  6.46413027e-05 4.97457477e-05 1.81662656e-07 3.82199460e-06\n",
            "  1.00168450e-06 3.41307839e-07 7.66893535e-08 9.19137264e-08\n",
            "  1.96106062e-10 8.58958238e-09 6.86125122e-06 2.20106576e-05\n",
            "  6.61257701e-03 1.90473293e-04 1.46893697e-04 3.07837195e-06\n",
            "  3.05504926e-07 1.16759102e-09 2.52173486e-05 8.20220350e-07\n",
            "  1.88312391e-04 4.09958056e-06 1.41093381e-07 1.76322271e-06\n",
            "  1.35940127e-05 2.33952775e-07 3.97910344e-06 2.82246965e-05\n",
            "  1.90762307e-07 7.16311774e-08 2.33485048e-06 1.21456594e-07\n",
            "  1.82917734e-08 9.87232849e-02 6.80141920e-06 4.82218319e-08\n",
            "  2.48584172e-07 1.08657751e-07 2.61342138e-05 2.90931639e-05\n",
            "  1.29763947e-07 5.15692091e-06 1.26236355e-05 2.39261226e-06\n",
            "  1.49837888e-07 1.20235541e-07 7.42476583e-02 1.30432658e-04\n",
            "  1.73154297e-06 2.72669495e-05 5.15801548e-05 8.98792223e-06\n",
            "  4.82180167e-06 1.38320075e-07 2.62385754e-07 2.30017504e-05\n",
            "  3.87903456e-05 1.40445508e-07 3.28879565e-07 1.13363887e-08\n",
            "  7.14544964e-04 1.02444369e-06 1.54036086e-03 8.42626148e-04\n",
            "  2.38017469e-06 4.71962309e-08 5.19429477e-06 1.46817843e-06\n",
            "  3.11726353e-07 1.37628027e-04 2.53139820e-06 4.48643704e-07\n",
            "  1.55798538e-04 7.63200660e-05 3.41192305e-07 1.41192459e-07\n",
            "  1.21897088e-07 1.32183077e-05 1.18223966e-06 2.39743968e-04\n",
            "  5.79169068e-07 3.50033929e-06 1.36144720e-07 1.60868160e-06\n",
            "  1.94293407e-05 8.63796322e-06 2.27158261e-03 3.49230868e-05\n",
            "  4.99342548e-07 5.59038541e-04 4.40735494e-05 1.25128304e-06\n",
            "  4.35627953e-06 1.86998000e-06 1.36716346e-06 8.92606840e-06\n",
            "  1.18144889e-07 1.27169432e-03 8.54425980e-06 8.55388720e-08\n",
            "  8.05742033e-08 1.95744235e-07 6.10786174e-06 5.64771790e-06\n",
            "  5.55853262e-07 1.35595383e-06 1.43790757e-07 3.02440276e-05\n",
            "  1.98715225e-06 1.89662302e-07 1.44772530e-05 7.03294575e-07\n",
            "  1.33795922e-07 6.84515612e-07 6.95511337e-09 2.00114997e-07\n",
            "  8.21120411e-05 2.36529930e-04 3.72842886e-04 4.49670011e-07\n",
            "  2.43384857e-04 2.03398435e-04 1.16037018e-05 9.18293097e-07\n",
            "  2.31624412e-07 1.89443148e-04 6.28304463e-07 3.32600877e-07\n",
            "  7.51135871e-04 1.55112264e-06 3.13850069e-06 5.82397881e-08\n",
            "  3.63457033e-08 8.31108537e-07 2.28054647e-04 2.19315169e-07\n",
            "  2.06356908e-05 7.04801596e-06 1.40715326e-06 5.04750915e-07\n",
            "  2.15125215e-06 1.07849601e-05 4.53495386e-06 9.82187885e-06\n",
            "  2.41259349e-05 2.18758260e-07 5.39301000e-05 1.25835149e-05\n",
            "  4.24500431e-05 3.16453429e-06 2.74253427e-04 1.20734003e-05\n",
            "  5.98186443e-06 1.93828691e-05 1.23612874e-04 8.49677633e-07\n",
            "  1.85632587e-07 8.36654195e-08 1.49822763e-05 1.65764377e-05\n",
            "  4.23704114e-05 1.10540735e-04 1.00852264e-06 2.32717994e-05\n",
            "  9.27117799e-06 4.41792827e-06 3.22625692e-06 6.32111266e-07\n",
            "  1.07112015e-02 5.50840050e-05 1.30558110e-04 1.73636417e-05\n",
            "  4.59435687e-04 4.51464416e-07 3.98107950e-05]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(probabilities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVlt-6fcornx",
        "outputId": "7d113b0c-3c83-46a1-8488-598a550b48ec"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# index with highest probability\n",
        "for _ in range(next_words):\n",
        "  predicted = np.argmax(probabilities, axis = -1)[0]"
      ],
      "metadata": {
        "id": "ipxmpbnaovxa"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlvQjQkTpHgf",
        "outputId": "c04309b3-0d1c-436f-d4a1-600ce235e0cd"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore if index is 0 because that is just the padding\n",
        "\n",
        "for _ in range(next_words):\n",
        "  if predicted != 0:\n",
        "\n",
        "    output_words = tokenizer.index_word[predicted]\n",
        "\n",
        "    seed_text = seed_text + ' ' + output_words\n",
        "\n",
        "print(seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZUniNYtpJs3",
        "outputId": "3e8be124-2c46-473b-a851-b192bb0f4323"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ankur went to Dublin they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they they\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define seed text\n",
        "seed_text = \"Ankur went to Dublin\"\n",
        "\n",
        "# Define total words to predict\n",
        "next_words = 100\n",
        "\n",
        "# Loop until desired length is reached\n",
        "for _ in range(next_words):\n",
        "\n",
        "\t# Convert the seed text to a token sequence\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\n",
        "\t# Pad the sequence\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\t\n",
        "\t# Feed to the model and get the probabilities for each index\n",
        "  probabilities = model.predict(token_list)\n",
        "\n",
        "  # Pick a random number from [1,2,3]\n",
        "  choice = np.random.choice([1,2,3])\n",
        "\t\n",
        "  # Sort the probabilities in ascending order \n",
        "  # and get the random choice from the end of the array\n",
        "  predicted = np.argsort(probabilities)[0][-choice]\n",
        "\n",
        "\t# Ignore if index is 0 because that is just the padding.\n",
        "  if predicted != 0:\n",
        "\t\t\n",
        "\t\t# Look up the word associated with the index. \n",
        "\t  output_word = tokenizer.index_word[predicted]\n",
        "\n",
        "\t\t# Combine with the seed text\n",
        "\t  seed_text += \" \" + output_word\n",
        "\n",
        "# Print the result\t\n",
        "print(seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu7HGYzyqCRR",
        "outputId": "7077772c-409c-4637-e9a1-69a98a758c15"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ankur went to Dublin dancing away all round a reel them and me a jig rose brothers a call man me friends her wall relations groups man entangled again her call call whirligig wall wall man i a jig small further further mchugh hall minute entangled entangled groups groups wall runctions brooks old hall hall hall brothers ball ball groups groups wall wall hearty entangled entangled again runctions doing out the girls and hearty hearty hearty hearty taras old polkas lads ask ned brothers lanigans for ball and gathered brooks pound might table nonsense eyes water gathered a farm all steps they lanigans and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aOV2zXJQrCMa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}